\documentclass[]{article}

\usepackage{enumitem}
\setlist[description]{style=nextline}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{stmaryrd}
\usepackage{bbm}  % \mathbb{1}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
    \usepackage{unicode-math}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage[]{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\PassOptionsToPackage{hyphens}{url} % url is loaded by hyperref
\usepackage[unicode=true]{hyperref}
\hypersetup{
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage[margin=1cm]{geometry}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{0}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

% set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother

\usepackage{proof}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{proof}
\usepackage{textcomp}

\newcommand \braces[1] {\{ #1 \}}
\renewcommand \phi {\varphi}

\newcommand \Z        {\mathbb Z}
\newcommand \intersect  {\cap }
\newcommand \union      {\cup }

\newcommand \FO       {\text{FirstOrderFormula}}
\newcommand \model    {\text{mod}}
\newcommand \proves   {{\vdash}}
\renewcommand \lor     {\vee }
\newcommand \Or     {\bigvee}
\renewcommand \And    {\bigwedge}
\newcommand \limplies {\longrightarrow }

\newcommand \sig             {\text{sig}}
\newcommand \fun             {\text{fun}}
\newcommand \pred            {\text{pred}}
\newcommand \vars     {\text{vars}}
\newcommand \F        {\mathcal F}
\newcommand \QF       {\text{QF}}
\newcommand \Lit      {\text{Lit}}

\newcommand \rewrite  {\longrightarrow_R}
\newcommand \rewrites {\longrightarrow_R}
\newcommand \terms    {T_{\Sigma}}

\newcommand \purified        {\And\Lit(\Sigma_1) \land \And\Lit(\Sigma_2) \land \Lit(\Sigma_0)}
\newcommand \arrangements    {\Or\{\ \}}

\newcommand \SharedSorts     {S_0}
\newcommand \SharedVariables {X^{1, 2}}
\newcommand \onetwo {\{1, 2\}}
\newcommand \Equiv {\text{Equiv}}

\newcommand \NelsonOppenSat {\text{NelsonOppenSat}} 
\newcommand \CheckSat       {\text{CheckSat}} 
\newcommand \CandidateEqualities {\text{CE}}

\date{}

\usepackage{fancyhdr}
\usepackage{lastpage}
\pagestyle{fancy}
\fancyhf{}
\lhead{  }
\rhead{  }
\rfoot{Page \thepage\ of \pageref{LastPage}}

\begin{document}

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

In 1928, David Hilbert posed the ``Entscheidungsproblem'' (``the
decision problem'') to the mathematical community -- a challenge to find
an algorithm that takes as input any first-order logic statement and
return whether it is a true statement or not. Even though, in 1936, Alan
Turing and Alonzo Church independently showed that such an algorithm is
impossible, great progress has been made towards solving significant and
profitable subsets of first-order logic formulae.

Given a theory and a first order logic formula in it's signature, the
Satisfiability Modulo Theories problem is that of deciding whether there
is an assigment of variables such that the interpretation of that
forumla holds in some model of that theory. In this case, we say that
the forumla is ``satisfiable''. Otherwise we say that the formula is
``unsatisfiable''. Validity, an important related concept, is the dual
of satisfiability. A formula is ``valid'' in a theory, if in every model
of the theory and for every possible assigment of variables, the formula
holds. For example, the statement ``every natural number factorizers
uniquely into a set of prime numbers'' is valid, whereas the first order
logic statement ``Peano arithmetic is consistent'', in the theory of
Peano arithmetic, is not (Godel's Second Incompleteness Theorem means
that there is a non-standard model where a where a non-standard number
encodes a proof for the inconsistency of Peano Arithmetic).

Although in general SMT is undecidable (e.g.~for non-linear integer
arithmetic), there are subsets of theories that are decidable and
immensely useful for a variety of applications including solving
optimization problems, program verification and automated theorem
proving.

Over the years, efficient algorithms were devised for linear real and
integer arithmetic, non-linear arithmetic, arrays (partial functions
from the naturals) amongst others, as well as theory-generic
algorithms{[}@sat-modulo-nothing{]}{[}@sat-modulo-ac{]}. Program
verification and other applications, however, often involve working with
a combination of two or more theories (e.g.~verification of a sorting
algorithm may involve using the combined theory of arrays and of total
linear orders). Initially, solving satisfiability problems in a
combination of theories involved manually working out the combined
procedure and proving their correctness{[}@XXX{]}. In 1979, Greg Nelson
and Derek Oppen published a generic method for composing SMT solvers for
two theories into one for the quantifier free fragment of their union
{[}@nelson-oppen{]}. Today, most SMT solvers use the Nelson-Oppen
algorithm at their core.

In this thesis, we implement in rewriting logic the order-sorted
Nelson-Oppen algorithm for composing satisfiability modulo theory (SMT)
solvers for first order theories into an SMT solver for the
quantifier-free fragment of their union. We build on the Tenelli's work
of extending the Nelson-Oppen algorithm to order-sorted logics
{[}@tinelli-order-sorted{]} and refer to the notes of Meseguer
{[}@cs576{]}, to implement this algorithm as an order-sorted rewrite
theory using the Maude System.

Implementing this as a rewrite theory is particularly attractive for
several reasons. Firstly, the inference rules translate almost directly
into axioms of the equational theory making the algorithm much clearer
than it would be in, e.g.~C++. Secondly, many first order logic theories
can be defined as equational theories (a subset of rewrite theories).
This, in combination with, rewriting logic being a reflective logic
allows implementing theory generic SMT solvers such as Variant-Based
Satisfiability{[}@var-sat{]} and congruence closure possible. In
particular, these solvers have been implemented in
Maude{[}@skerik-var-sat{]} taking advantage of reflection through
Maude's \texttt{META-LEVEL}.

The Maude System is a programming language whos semantics are based in
Rewriting Logic. As such, there is little to no representational
distance between a rewriting theory and its implementation in Maude. It
is often used for modeling and verification of systems. It has been used
to verify a wide spectrum of systems, from biological systems (Pathway
Logic {[}@pathwaylogic{]}), to Network Protocols (Maude NPA {[}@NPA{]}),
to concensus algorithms, and programming languages (KFramework
{[}@kmaude{]}). The capabilities of many of these formal verification
tools can be substantially increased through leveraging the power of SMT
solvers. Besides the SMT solvers mentioned previously, Maude also offers
access to the CVC4{[}@BCD+11{]} solver as well as Yices2, both industry
standard solvers. While both CVC4 and Yices2 themselves implement the
Nelson-Oppen algorithm internally, it does not allow cooperation between
the algorithms implemented in Maude as rewrite theories, or other
solvers. Thus this implementation of the algorithm can be seen as a
first step towards a rich, robust and extensable ecosystem of
cooperating SMT solvers.

\hypertarget{satisfiability-modulo-theories-smt}{%
\subsection{Satisfiability Modulo Theories
(SMT)}\label{satisfiability-modulo-theories-smt}}

SMT problems are decision problems for checking whether a first-order
logic formula \(\phi(\vec x)\) is satisfiable in a theory \(T\),
i.e.~whether there is a model \(M\) of \(T\) such that
\(M \models \exists \vec x \phi(\vec x)\). Similarly, a formula is said
to be valid if its negations is unsatisfiable.

Checking satisfiabilty and its dual validity have a wide range of
applications, including logistics, optimization, software verification
and program synthesis.

SMT has come a long way since Hilbert posed his problem of ``mechanising
mathematics''.

In 1929, Persberger proved that linear integer arithmetic is indeed
decidable, and although it was shown by Fischer and Rabin that algorithm
must be worst case doubly exponential in the length of formulae, the
Simplex Algorithm and its variations has proven to be an effective
method of solving SMT for both real and integer quantifier free linear
arithmetic.

There are efficient solvers for the boolean satisfiability problem.

The concept of ``validity'' is central to automated reasoning, and
although Church and Turing have showed that the search for a general
algorithm for checking validity (i.e. ``automating mathematics'') is
futile,

\begin{itemize}
\item
  effective quantifier elemenation
\item
  \begin{enumerate}
  \def\labelenumi{(\arabic{enumi})}
  \setcounter{enumi}{1928}
  \tightlist
  \item
    Persberger: linear arithmetic is decidable
  \end{enumerate}

  \begin{itemize}
  \tightlist
  \item
    (although the general algorithm was later shown to be worst case
    doubly exponential on the length of the formula)
    {[}@Fischer-and-rabin{]}
  \item
    (Simplex method)
  \end{itemize}
\item
  define

  \begin{itemize}
  \tightlist
  \item
    FOL formula describing constraints over a set of variables, and a
    theory T deciding if there is an assignment of variables
  \item
    Validity
  \end{itemize}
\item
  Examples

  \begin{itemize}
  \tightlist
  \item
    Linear and non-linear Programming
  \item
    Boolean satisfiability
  \end{itemize}
\item
  Motivation

  \begin{itemize}
  \tightlist
  \item
    Automated theorem proving
  \item
    Formal program verification
  \item
    Optimization problems
  \end{itemize}
\item
  The importance of SMT to these applications has

  \begin{itemize}
  \tightlist
  \item
    led to the industry standardizing on an interface to solvers (the
    SMT2 format)
  \item
    There is an annual competition SMT-COMP where implementations
    compete
  \end{itemize}
\item
  Quantifier free vs Quantified
\item
  Historically

  \begin{itemize}
  \tightlist
  \item
    Methods for individual theories
  \item
    Prior to 1979, when wanted combination, had to manually work it out
  \item
    Nelson-Oppen combination changed that.

    \begin{itemize}
    \tightlist
    \item
      Although initially published as a general combination method for
      any QF FOL theories later discovered that there were some basic
      criteria
    \item
      Further work generalized the algorithm to work for ``Shiney'' and
      ``Polite'' theories.
    \item
      Was also modified to work with Order-Sorted Logics
    \end{itemize}
  \end{itemize}
\end{itemize}

\hypertarget{maude}{%
\subsection{Maude}\label{maude}}

The Maude System is a programming language and framework whos semantics
are based in Rewriting Logic. As such, there is little to no
representational distance between a rewriting theory and its
implementation in Maude. It is often used for modeling and verification
of systems. It has been used to verify a wide spectrum of systems, from
biological systems (Pathway Logic {[}@pathwaylogic{]}), to Network
Protocols (Maude NPA {[}@NPA{]}), to concensus algorithms, and
programming languages (KFramework {[}@kmaude{]}). The capabilities of
many of these formal verification tools can be substantially increased
through leveraging the power of SMT solvers. Besides the SMT solvers
mentioned previously, Maude also offers access to the CVC4{[}@BCD+11{]}
solver as well as Yices2, both industry standard solvers. While both
CVC4 and Yices2 themselves implement the Nelson-Oppen algorithm
internally, it does not allow cooperation between the algorithms
implemented in Maude as rewrite theories, or other solvers. Thus this
implementation of the algorithm can be seen as a first step towards a
rich, robust and extensable ecosystem of cooperating SMT solvers.

\hypertarget{logical-foundations-of-maude}{%
\subsubsection{Logical Foundations of
Maude}\label{logical-foundations-of-maude}}

Maude derives its semantics from order-sorted rewriting logic. In
particular, the model used is the initial model XXX.

\hypertarget{unsorted-vs-many-sorted-vs-order-sorted-logics}{%
\paragraph{Unsorted vs Many-Sorted vs Order-Sorted
Logics}\label{unsorted-vs-many-sorted-vs-order-sorted-logics}}

Traditionally, first order logic has been used in an unsorted setting.
This can however make representing some theories cumbersome. For
example, in the theory of vector spaces there are two types of objects
that are of interest to us: \emph{vectors} and \emph{scalars}. If we
approach this by defining a signature whose terms can represent either
vectors or scalars, along with predicates for checking whether an
element is a vector or a scalar, functions on vectors would become
partial. We could work around this by adding a third ``type'' of element
to represent invalid results for these functions, but this quickly
becomes annoying.

Many sorted signatures offer a solution\ldots{} - XXX define

However, we run into another problem. Take the theory of lists. The head
function takes a non-empty list and returns its first element. But, what
happens when the list is empty? If we try to define a special value
``undefined'' that head returns when the list is empty\ldots{}

Order Sorted Logics add a partial order on sorts. - xxx define We can
now define head as a total function from NeList to Elem

\hypertarget{operates-over-the-initial-models-of-these-theories}{%
\paragraph{Operates over the initial models of these
theories}\label{operates-over-the-initial-models-of-these-theories}}

\hypertarget{rewriting-and-equational-logic}{%
\paragraph{Rewriting and equational
logic}\label{rewriting-and-equational-logic}}

Maude is based on two logics, one contained in the other. The first,
equational logic, is the Horn logic fragment of order-sorted first-order
logic with equality for signatures involving only function symbols. The
second, rewriting logic, defines a directed graph over elements of
models of an equational theory. These allow capturing non-deterministic
behaviour in models, which the equational subset does not allow.

\hypertarget{equational-logic}{%
\paragraph{Equational Logic}\label{equational-logic}}

A \emph{signature} \(\Sigma\) is a set of function symbols and their
arities. An \emph{equational theory} is a pair \((\Sigma, E)\), where
\(E\) is a set of algebraic identities on the terms \(\terms\)
constructed from the signature \(\Sigma\). For example, the group
\(\Z_5\) could be described as an equational theory as follows:
\[\Sigma = \{ 0, 1, \_+\_, -\_ \}\]

Note that underscores in the signature indicate holes for subterms, and
thus indicate the arity of the symbol.

\[\begin{aligned}
x + 0                     &= x                     &\quad\quad& \text{Additive Identity}   \\
x + (y + z)               &= (x + y) + z           &\quad\quad& \text{Associativity}       \\
x + y                     &= y + x                 &\quad\quad& \text{Commutativity}       \\
1 +  1 +  1 +  1 + 1      &= 0                     &\quad\quad& \text{Characteristic 5}    \\
x + (-x)                  &= 0                     &\quad\quad& \text{Inverses}            \\
\end{aligned}\]

XXX: The trivial group also models this. Do we need to some how state
that 0 != 1 or that it is the initial model?

This equational theory can be implemented as a Maude \emph{functional
module} as follows:

\begin{verbatim}
fmod Z5 is
    sorts Z5 .
    op 0 : -> Z5                              [ctor] .
    op 1 : -> Z5                              [ctor] .
    op _ + _ : Z5 Z5 -> Z5   [assoc comm id: 0 ctor] .
    op   - _ : Z5    -> Z5                           .

    vars x y : Z5                        . --- x and y are variables of sort Z5
    eq 1 + 1 + 1 + 1 + 1 = 0             . --- Characteristic 5
    eq -(x + y)          = (-x) + (-y)   . --- Inverse distribute
    eq (-1)              = 1 + 1 + 1 + 1 . --- Inverse of 1
endfm
\end{verbatim}

This program represents an equational theory
\(E = ((S, \le_S), \Sigma, E \union B)\). Here,
\(S = \braces{\tt Z5}\, \le_s = \braces{{\tt NzZ5}, {\tt Z5}}\) and
\(\Sigma = \braces{ {\tt 0}, {\tt 1}, {\tt \_ + \_}}\). The
\texttt{fmod\ Z5\ is\ ...\ endfm} construct defines a \emph{functional
module} and describes an equational theory. The signature of this theory
has a single sort \texttt{Z5} The \texttt{op} declaration defines the
terms and functions in the signature of that theory. These are of the
form
\texttt{op\ NAME\ :\ ARGUMENTS\ -\textgreater{}\ RESULT\ {[}ATTRIBUTES{]}}.
For example, \texttt{\_\ +\ \_} takes two terms of sort \texttt{Z5} and
returns another of the same sort, while \texttt{0} and \texttt{1} are
constants of sort \texttt{Z5}. The \texttt{ctor} attribute marks a term
as part of the constructor signature of the theory. The \texttt{assoc},
\texttt{comm} and \texttt{id:\ 0} attributes mark the plus operator as
being associative, commutative and having \texttt{0} as its identity.
The \texttt{vars} declaration allows using the tokens \texttt{x} and
\texttt{y} as variables in equations. Each \texttt{eq} construct
represents an axiom in the equational theory.

Although ordinarily equations in equational theories are symmetric -- in
a proof we may replace equals by equals if a term matches either the
left hand side or the right hand side -- equations in Maude are only
applied from left to right. This is to allow defining a terminating
execution. Attributes like \texttt{assoc} and \texttt{comm} allow
specifying common axioms that would otherwise be difficult to define in
a terminating manner (and also make implementation of Maude's matching
and unification algorithms easier and more efficient.) Because of this
directionality, the theories must be \emph{confluent} for them to form a
well-defined equational theory. i.e.~the application of equations must
yield the same final result irrespective of the order in which they are
applied. Although tools such as the Church-Rosser Checker and the Maude
Termination Tool are provided, the burden of making sure that functional
modules are confluent and terminating is ultimately on the programmer
defining them. This orientation on the equations means that we will
sometimes have to define equations that would otherwise be
mathematically deducible. For example, if we had defined the functional
module with the same eqautions as the equational theory, Maude would not
have been able to deduce that \(-3 = 2\). However, it is trivial that
each set of equations can be derived from the other. Inspite of this, we
can be seen from the example above that the representational distance
between an equational theory and its implementation in Maude very small.

Besides the syntax demonstrated above, Maude also supports conditional
equations, i.e.~an equation that holds when some predicate over the term
holds, and also an ``otherwise'' clause -- an equation that will fire
when no other equation holds.

\hypertarget{rewriting-logic}{%
\paragraph{Rewriting Logic}\label{rewriting-logic}}

A rewrite theory \(\mathcal R\) is the triple \((\Sigma, E, R)\), where
\((\Sigma, E)\) is an equational theory and \(R\) the set of \emph{one
step rewrites} on the terms of the signature.

The rewrite rules \(R\) define a relation
\(\rewrite \subset \terms\times\terms\). This relation is obtained from
the closure of \(R\) under \emph{reflexivity}, \emph{\(E-\)equality}
(equality under the set of axioms \(E\)), \emph{congruence} (if a
subterm rewrites, then the rewrite ``lifts'' to all terms containing
that subterm;
\(t \rewrite t' \implies f(\ldots, t, \ldots) \rewrite f(\ldots, t', \ldots)\)),
\emph{replacement} (for any substitution \(\theta\),
\(t \rewrite t' \implies t\theta \rewrite t'\theta\)) and
\emph{transitivity}.

If \(x \rewrites y\), we say ``\(x\) rewrites to \(y\)''.

This relation defines a Kripke structure -- a transition graph over the
possible set of states of a system. It is over this structure that modal
logics like Linear and Branching Temporal Logics are defined. Kripke
Structures are commonly used in model checking and are the structures
over which Linear and Branching Temporal Logics are defined. Again, this
makes the representational distance between the specification of the
model and the data structures we use to reason over it minimal, making
verification of correctness of model checkers and other tools that
reason over these structures easy.

Rewrite theories are defined in maude through \emph{system modules}.
Since we implement the Nelson-Oppen combination algorithm purely as a
functional module, we do not go into the details of the syntax the
syntax for system modules here.

\hypertarget{reflective-logic}{%
\paragraph{Reflective logic}\label{reflective-logic}}

Rewriting logic is a \emph{reflective logic} -- its meta theory can be
represented at the object level in a consistent way. i.e.~there is a
\emph{universal theory} \(U\) and a function
\(\overline { ( \_ \proves \_ ) }\) such that for any theory \(T\),
\(T \proves \phi \iff U \proves \overline{ T \proves \phi }\). This is
particularly interesting because it allows us to reason it allows us to
implement both the models we work over and the model checking tools we
use in the same langauge. In fact, the implementation of variant-based
satisfiability by Stephen Sherik and of the Nelson-Oppen Combination
Algorithm take advantage of this.

In Maude, the built-in module \texttt{META-LEVEL} is used to do this
lifting. Terms are represented in the sort \texttt{Term}, and modules in
the sort \texttt{Module}. The function
\texttt{upModule\ :\ ModuleExpression\ Bool\ -\textgreater{}\ Module}
takes a \texttt{ModuleExpression}, a quote followed by the module name
(e.g. \texttt{\textquotesingle{}Z5}) and returns a term representing the
module. Similarly, the function
\texttt{upTerm\ :\ Universal\ -\textgreater{}\ Term} takes a term of any
sort and returns a meta-term of sort \texttt{Term}. Terms at the
meta-level are represented using quoted identifiers. Arguments to terms
are placed in a comma separated list within square brackets. Constants
and variables have their sorts annoted as part of the identifier. For
example the term \texttt{1\ +\ 1} is represented at the meta level as
\texttt{\textquotesingle{}\_+\_{[}\ \textquotesingle{}1.Z5,\ \textquotesingle{}1.Z5\ {]}},
while the variable \texttt{X} as \texttt{\textquotesingle{}X:Z5}.
Meta-terms can be reduced using the \texttt{metaReduce} function.

\texttt{META-LEVEL}'s \texttt{upModule} function allows us to lift a
theory and perform rewrites with it like any other term.

\hypertarget{decision-procedures-in-maude}{%
\subsubsection{Decision Procedures in
Maude}\label{decision-procedures-in-maude}}

Some satisfiability procedures have been been implemented in Maude using
the \texttt{META-LEVEL}. We will use these solvers as the subsolvers for
Nelson-Oppen.

\hypertarget{variant-based-satisfiability}{%
\paragraph{Variant-based
Satisfiability}\label{variant-based-satisfiability}}

Variant-based satisfiability is a theory-generic procedure that applies
to a large set of user-definable order-sorted signature. The equations
of this theory must satisfy the \emph{finite variant property} and may
include axioms such as commutativity, associativity-commutativity or
identity. Refer to {[}@varsat{]} for a more in-depth description.

Let \(T = (\Sigma, E \union B)\) where the equations \(E\) are
confluent, terminating and \(B\)-coherent modulo axioms. A
\(E,B-\)variant of a term \(t\) is a pair \((u, \theta)\) such that
\(u =_B (t\theta)!_{\vec E,B}\), where for any term \(u\),
\(u!_{\vec E, B}\) denotes the fully simplified term obtained by
exhaustive simplification with the oriented equations \(\vec E\) modulo
\(B\). Given variants \((u, \theta)\) and \((v, \gamma)\) of \(t\),
\((u, \theta)\) is more general than \((v, \gamma)\) iff there is a
substitution \(\rho\) such that:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(\theta\rho =_B \gamma\) and
\item
  \(u\rho =_B v\)
\end{enumerate}

A theory \(T\) has the finite variant property (FVP) iff for each term
\(t\) there is a finite most general complete set of variants. If a
theory \((\Sigma, E\union B)\) is FVP and \(B\) has a finitary
\(B-\)unification algorithm, then folding variant narrowing gives a
finitary \(E\union B\)-unification algorithm {[}@XXX{]}.

Furthermore, if
\((\Sigma, E \union B) \supseteq (\Omega, E_{\Omega} \union B_\Omega)\)
is a subsignature of constructors and
\((\Omega, E_{\Omega} \union B_\Omega)\) is OS-compact, then
satisfiability of quantifier free formulae in this theory are decidable
by variant-based satisfiablity. This has been implmented in Maude by
Sherik and Meseguer{[}@metalevelvarsat{]} and will be used for
demonstrating the order-sorted Nelson-Oppen combination method.

\hypertarget{cvc4}{%
\paragraph{CVC4}\label{cvc4}}

CVC4 is an industry-standard automatic theorem prover that supports many
theories including rational and integer linear arithmetic, array,
bitvectors and a subset of non-linear arithmetic. Although CVC4 allows
defining algebraic data types it does not allow these user-defined types
to have equations over them. Thus its power can clearly be augmented by
combination with variant-based satisfiability.

\hypertarget{yices-2}{%
\paragraph{Yices 2}\label{yices-2}}

Yices 2 is another industry-standard SMT solver that is handles queries
non-linear arithmetic efficiently.

XXX Find some sort of interpretation of SMT-COMP results to compare
where Yices vs SMT are stronger

\hypertarget{order-sorted-nelson-oppen-as-a-rewrite-theory}{%
\section{Order Sorted Nelson Oppen as a rewrite
theory}\label{order-sorted-nelson-oppen-as-a-rewrite-theory}}

\[\infer[\text{Equality Propagation}]
{ \begin{matrix*}[l]
        & \CheckSat(\phi_j \land \phi_E \land x_m = x_n) \\
  \land & \NelsonOppenSat(\phi_1 \land \phi_2 \land \phi_E \land x_m = x_n, \CandidateEqualities \setminus \{x_m = x_n\})
  \end{matrix*}
}
{ x_m = x_n \in \CandidateEqualities
& T_i \models \phi_i \and \phi_E \implies x_m = x_n
& \NelsonOppenSat(\phi_1 \land \phi_2 \land \phi_E, \CandidateEqualities)
}
\]

\[\infer[\text{Split}]
{\Or_{x_m = x_n \in \CandidateEqualities}
 \left(\begin{matrix*}[l]
      &      &\CheckSat(\phi_1 \land \phi_E \land x_m = x_n) \\
      &\land & \CheckSat(\phi_2 \land \phi_E \land x_m = x_n) \\
      &\land & \NelsonOppenSat(\phi_1 \land \phi_2 \land \phi_E, \CandidateEqualities \setminus \{x_m = x_n\})
 \end{matrix*}\right)
}
{
& T_i \models \phi_i \and \phi_E \implies \And \CandidateEqualities
& \NelsonOppenSat(\phi_1 \land \phi_2 \land \phi_E, \CandidateEqualities)
}
\]

\hypertarget{conditions-on-the-theories}{%
\subsection{Conditions on the
theories}\label{conditions-on-the-theories}}

For the Nelson Oppen method to be viable, the order-sorted theories must
meet the following conditions:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  They must be stably infinite
\item
  They must be optimally intersecting.
\end{enumerate}

\begin{description}
\item[Stably Infinite]
Let \(T\) be an order-sorted first-order theory with signature
\(\Sigma = ((S, \le), F, P)\) and \(s_1, s_2,\ldots s_n \in S\). Let
\(\F \subset \FO(\Sigma)\), be the set of first order formulae in
\(\Sigma\)

\(T\) is stably infinite in sorts \(s_1, s_2,\ldots s_n\) for
\(\F-\)satisfiability iff every \(T-\)satisfiable formula
\(\phi \in \F\), is also satisfiable in a model
\(\mathcal B = (B, \__B) \in \model(T)\) such that
\(|B_{s_i}| \ge \chi_0, 1 \le i \le n\).

Intuitively, it means that we can always find models of both theories
where the cardinalities of sorts \(s_1, \ldots, s_n\) agree.
\end{description}

Notation: For sort \(s\) and signature \(\Sigma_i\), let \([s]_i\)
denote it's connected component of sorts in \(\Sigma_i\)

\begin{description}
\item[Optimally intersectable {[}@cs576{]}]
The order-sorted signatures \(\Sigma_1\) and \(\Sigma_2\) are optimally
intersectable iff:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Functions and predicates sorts agree:} For each
  \(f \in \fun(\Sigma_1) \intersect \fun(\Sigma_2)\) (resp,
  \(p \in \pred(\Sigma_1) \intersect \pred(\Sigma_2)\)),
  \(\exists \{i, j\} \in \onetwo\) such that:

  \begin{itemize}
  \item
    \(F_i(f) = F_j(f) \intersect ([s_1]_i\times\cdots\times [s_m]_i) \times [s_i]\)
    (resp
    \(P_i(p) = P_j(p) \intersect ([s_1]_i\times\cdots\times [s_m]_i)\)
  \item
    \([s_l] \subset [s_l]_j, 1 \le l \le n\), and
    \([s]_i \subset [s]_j\) (resp.
    \([s_l]_i \subset [s_l]_j, 1 \le l \le n\)).
  \end{itemize}
\item
  \textbf{Intersection is a single component:} For every sort
  \(s \in \SharedSorts\), we have
  \([s]_1 \intersect S_2 = [s]_2 \intersect [s]_1 = [s]_1\intersect [s]_2\)
\item
  and, for any two sorts \(s_i \in S_i\) and \(s_j \in S_j\) any one of:

  \begin{enumerate}
  \def\labelenumii{\roman{enumii}.}
  \item
    \textbf{Intersection is empty}:
    \([s_i]_i \intersect [s_j]_j = \emptyset\)
  \item
    \textbf{Intersection is the top sort of one component:}
    \([s_i]_1 \intersect [s_j]_2 = \{s_0\}\), where \(s_0\) is the
    top-sort of at least one of the connected components.
  \item
    \textbf{Once component is subsumed in the other:}

    \begin{enumerate}
    \def\labelenumiii{\alph{enumiii}.}
    \tightlist
    \item
      \(\exists k \in \onetwo\) and \([s_k]_k\) has a top sort,
      \([s_k]_k \subset [s_l]_l\) \(\{k, l\} = \onetwo\).
    \item
      \(\le_k \intersect [s_k] = \le_l \intersect [s_k]_2^2\)
    \item
      (downward closure):
      \(\forall s \in [s_l]_l, \forall s' \in [s_k]_k, s\le_l s' \implies s\in [s_k]_k\)
    \end{enumerate}
  \end{enumerate}
\end{enumerate}
\end{description}

\hypertarget{overview}{%
\subsection{Overview}\label{overview}}

Given two order-sorted, optimally intersecting, stably-infinite theories
\(T_1\) and \(T_2\) with signatures \(\Sigma_1\) and \(\Sigma_2\) each
with decision procedures for quantifier free \(T_i\)-satisfiability we
want to derive a decision procedure for quantifier free
\(T_1 \union T_2\) satisfiability.

We can transform any formula \(\phi\) into an \emph{equisatisfiable}
formula in disjunctive normal form. Further, for each atom in such a
formula we can apply ``purification'' to obtain a formula where each
atom is in the signature of one of the two theories.

Now, our task has become to find a model \(M_0\) and an assignment
\(a: \vars(\phi) \to M_0\) such that \(M_0, a \models \purified\), where
\(\Sigma_0\) is the intersection of the two signatures. In general, this
requires knowing the semantics of each of the theories, but in the case
of stably infinite theories, the task is easier. With stable
infiniteness, since every satisfiable formula has an infinite model, if
we need a value distinct from a witness we have infinite choices for
either the value or the witness. i.e.
\[T_1 \union T_2 \not\models \phi \land \vec t_k \ne \vec t'_k 
\iff T_i \models \phi \limplies \vec t_k = \vec t'_k\] This means that
we do not need to find a specific arrangement, but just a satisfiable
equivalence relation of the shared variables. For any formula,
\(\purified\), we have an equisatisfiable formula
\(\Or_{equiv\in \Equiv(\SharedVariables)}\{ \purified \land \phi_{\equiv}\}\),
where \(\Equiv(\SharedVariables)\) is the set of partitions on the
shared variables \(\SharedVariables\) and \(\phi_\equiv\) is the formula
defining this equivalence relation. Since for stably infinite theories
we only care about the equivalence class being satisfiable, we can
project this formula onto each of the theories and check satisfiability.

\begin{figure}
$$\begin{matrix*}[l]
                    &    &                        &     & T_{\union}  \models& \QF(\Sigma_1 \union \sigma_2)                                              \\
\text{DNF}          &\iff&                        &     & T_{\union}  \models& \And \Lit(\Sigma_1 \union \sigma_2)                                        \\
\text{Purification} &\iff&                        &     & T_{\union}  \models& \And \Lit(\Sigma_1) \land \And\Lit(\sigma_2)                                \\
\text{Arrangement}  &\iff&                        &     & T_{\union}  \models& \Or ( \And \Lit(\Sigma_1) \land \And\Lit(\sigma_2) \land \And \phi_{\equiv} )\\
\text{Projection}   &\iff& \exists \phi_{\equiv}, &     & T_1 \models        & \And \Lit(\Sigma_1) \land \And \phi_{\equiv}                                \\
                    &    &                        &\text{and} & T_2 \models        & \And \Lit(\Sigma_2) \land \And \phi_{\equiv}
\end{matrix*}$$
\caption{Equisatisfiable formulae transformations on stably infinite theories we use for NO}
\end{figure}

\hypertarget{inference-rules-for-order-sorted-nelson-oppen}{%
\subsection{Inference rules for Order-Sorted
Nelson-Oppen}\label{inference-rules-for-order-sorted-nelson-oppen}}

Note that up to this point, we have only found a mathematically sound
way of finding satisfiability but do not yet have a viable efficient
algorithm. Checking each equivalence class for satisfiability is
infeasable as the number of equivalence classes grows exponentially with
the number of variables, even in the order sorted case where we can
restrict ourselves to equivalences capatable with the sort structure.

Instead we choose a Darwinian approach, pruning classes of equivalences
from the search space if an identification of a single pair of variables
implied by one theory is not satisfiable in another. For the non-convex
case, if any theory implies the disjunction of all remaining
identifications we branch our search, checking if at least one of the
remaining identifications is satisfiable.

We can think of each step of the algorithm as splitting the search space
into subsets where a single additional identification holds. If only a
single identification is implied equality propagation causes the
algorithm to decend into it. Otherwise, the split rule checks the
satisfiability of each of the sets in the split subspaces, and decends
into each satisfiable one.

Besides the names of the theories, \texttt{nelson-oppen-sat} requires
additional information about theories such as which procedure to use for
checking satisfiability. We use ``tagged formulae'' to represent this
information. For example, the term
\texttt{tagged(\textquotesingle{}1.Nat\ ?=\ \textquotesingle{}2.Nat,\ ((\textquotesingle{}mod\ \textgreater{}\ \textquotesingle{}NAT),\ (\textquotesingle{}check-sat\ \textgreater{}\ \textquotesingle{}var-sat)))}
represents the formula ``\(1 = 2\)'' in the module of \texttt{NAT}, and
that we should use the \texttt{var-sat} procedure to check its
satisfiability. In the implementation in Maude, these tagged formula are
represented by the sort \texttt{TaggedFormula} and sets of tagged
formulae by the sort \texttt{TaggedFormulaSet}. For rewriting logic
variables (not to be confused with variables part of the formula we are
rewriting over) of the sort \texttt{TaggedFormula} we use the variables
\texttt{TF1} and \texttt{TF2}, while for \texttt{TaggedFormulaSet} we
use \texttt{TFS}.

\begin{verbatim}
load foform.maude
load cterms.maude
load ../varsat/var-sat.maude
load smt.maude

fmod TAGGED-FOFORM is
    protecting FOFORM .
    sort TaggedFormula TaggedFormulaSet Tags Tag .
    subsorts Tag < Tags .
    subsorts TaggedFormula < TaggedFormulaSet .

    op tagged : FOForm? Tags -> TaggedFormula .
    op empty : -> Tags [ctor] .
    op _ ; _ : Tags Tags     -> Tags [ctor assoc comm id: empty] .
    op _ > _ : Qid  Qid      -> Tag . --- TODO Genneralize to QidSet?

    op empty : -> TaggedFormulaSet [ctor] .
    op _,_ : TaggedFormulaSet TaggedFormulaSet -> TaggedFormulaSet [ctor comm assoc id: empty] .
endfm
\end{verbatim}

\begin{verbatim}
fmod FOFORM-VARIABLES is
    protecting FOFORM .
    protecting VARIABLESET .

    vars PHI PHI' : FOForm .
    vars T1 T2 : Term .
    vars TL : TermList .
    vars X : Variable .

    op vars : FOForm   -> VariableSet .
    op vars : Term     -> VariableSet .
    op vars : TermList -> VariableSet .
    ----------------------------------
    eq vars(mtForm) = none .
    eq vars(tt)     = none .
    eq vars(ff)     = none .
    eq vars(PHI /\ PHI') = vars(PHI) ; vars(PHI') .
    eq vars(PHI \/ PHI') = vars(PHI) ; vars(PHI') .
    eq vars(T1 ?= T2) = vars(T1) ; vars(T2) .
    eq vars(T1 != T2) = vars(T1) ; vars(T2) .
    eq vars((T1, NETL:NeTermList)) = vars(T1) ; vars(NETL:NeTermList) .
    eq vars(Q:Qid[TL]) = vars(TL) .
    eq vars(X) = X .
    eq vars(T1) = none [owise] . --- TODO: Doable without owise?
endfm
\end{verbatim}

\begin{verbatim}
fmod FOFORM-TO-SMT is
    protecting META-TERM .
    protecting FOFORM .

    vars FO1 FO2 : FOForm .
    vars T1  T2  : Term   .

    op foform-to-smt : FOForm -> Term .
    op foform-to-smt : Term   -> Term .
    ---------------------------------------------------------------------------------
    eq foform-to-smt(tt)         = 'true.Boolean .
    eq foform-to-smt(FO1 /\ FO2) = '_and_  [foform-to-smt(FO1), foform-to-smt(FO2)] .
    eq foform-to-smt(FO1 \/ FO2) = '_or_   [foform-to-smt(FO1), foform-to-smt(FO2)] .
    eq foform-to-smt(T1  ?=  T2) = '_===_  [foform-to-smt(T1),  foform-to-smt(T2)]  .
    eq foform-to-smt(T1  !=  T2) = '_=/==_ [foform-to-smt(T1),  foform-to-smt(T2)]  .
    eq foform-to-smt(T1)         = T1          [owise] .
endfm
\end{verbatim}

\begin{verbatim}
fmod NO-CHECK-HELPER is
    protecting FOFORM .
    protecting TAGGED-FOFORM .
    protecting FOFORM-TO-SMT .
    protecting FOFORMSIMPLIFY .

    protecting VAR-SAT .

    op check-valid           : TaggedFormula -> Bool .
    op check-sat             : TaggedFormula -> Bool .
    op $check-sat.dnf        : TaggedFormula -> Bool .
    op $check-sat.print      : ModuleExpression FOForm Bool -> Bool .

    var ME   : ModuleExpression .
    var PHI  : FOForm           .
    var SAT? : Bool             .
    vars TS  : Tags             .

    --- strictNot gets stuck when it cannot evaluate further. This prevents
    --- `valid` from returning true if `sat` gets stuck
    op strictNot        : Bool -> Bool .
    op $strictNot.error : Bool -> Bool .
    ------------------------------
    eq strictNot(true)   = false .
    eq strictNot(false)  = true  .
    eq strictNot(B:Bool) = $strictNot.error(B:Bool) [owise print "----- what is? " B:Bool]  .

    op smt-sat : ModuleExpression FOForm -> Bool .
    eq smt-sat(ME, PHI)
     = metaCheck([ME], foform-to-smt(PHI))
     .

    eq check-valid(tagged(PHI, TS)) = strictNot(check-sat(tagged(~ PHI, TS))) .
    eq check-sat  (tagged(PHI, TS)) = $check-sat.dnf       (tagged(simplify(PHI), TS))
    .

    eq $check-sat.dnf       (tagged(PHI, ('mod > ME); ('check-sat > 'var-sat); TS))
     = $check-sat.print(ME, PHI, var-sat(upModule(ME, true), PHI))
---       [print "check-sat? " PHI]
     .

    eq $check-sat.dnf       (tagged(PHI, ('mod > ME); ('check-sat > 'smt-sat); TS))
     = $check-sat.print(ME, PHI, smt-sat(ME, PHI))
     .

    eq $check-sat.print(ME, PHI, SAT?) = SAT?
---    [print "check-sat: " ME ": " PHI " is " SAT? ]
     .

    eq smt-sat(ME, PHI) = metaCheck([ME], foform-to-smt(PHI))
     .
endfm
\end{verbatim}

\begin{verbatim}
fmod NELSON-OPPEN-COMBINATION is
    protecting NO-CHECK-HELPER .
    protecting FOFORM-DEFINEDOPS .
    protecting FOFORMSET .
    protecting FOFORMSIMPLIFY . protecting DNF . protecting NNF .
    protecting PURIFICATION .
    protecting TAGGED-FOFORM .
    protecting FOFORM-VARIABLES .
    protecting FOFORM-SUBSTITUTION .

    vars MCONJ1 MCONJ2 : Conj? .
    vars CONJ PHI1 PHI2 : Conj .
    vars PHI : QFForm .
    vars CANDEQ DISJ?1 DISJ?2 : Disj? .
    vars M1 M2 : Module .
    vars ME1 ME2 : Qid . --- TODO: Wierd, Qids are a subsort of ModuleExpr s not the other way around
    vars TFS : TaggedFormulaSet .
    vars TF1 TF2 : TaggedFormula .
    vars TS1 TS2 : Tags .
    vars X  X1  X2  : Variable .
    vars XS XS1 XS2 : VariableSet .
    vars T1 T2 : Term . var TL : TermList .

--- Tag a conjunction of wellFormed atoms into TaggedFormula. Atoms in the
--- intersection of multiple theories are copied into each tag.
--- TODO: Ill formed formulae are silently ignored.

    op tagWellFormed           : TaggedFormulaSet EqConj? -> TaggedFormulaSet .
    op tagWellFormed.hasConvex : TaggedFormulaSet EqConj? -> TaggedFormulaSet .
    op $tagWellFormed.filter   : ModuleExpression EqConj? -> EqConj? .
    -----------------------------------------------------------------------------
    eq tagWellFormed(TFS, CONJ) = tagWellFormed.hasConvex(addConvexTag(TFS), CONJ) .
    eq tagWellFormed.hasConvex(empty, CONJ) = empty .
    eq tagWellFormed.hasConvex((tagged(PHI1, ('mod > ME1); TS1 ), TFS), CONJ)
     = ( tagged(PHI1 /\ $tagWellFormed.filter(ME1, CONJ), ('mod > ME1) ; TS1)
       , tagWellFormed(TFS, CONJ)) .
    eq $tagWellFormed.filter(ME1, A:EqAtom /\ MCONJ2)
     = if A:EqAtom in upModule(ME1, true) then A:EqAtom /\ $tagWellFormed.filter(ME1, MCONJ2)
                                    else             $tagWellFormed.filter(ME1, MCONJ2)
                                    fi
     .
    eq $tagWellFormed.filter(ME1, TA:TruthAtom) = TA:TruthAtom .
    eq $tagWellFormed.filter(ME1, mtForm) = mtForm .

    op addConvexTag : TaggedFormulaSet -> TaggedFormulaSet .
    --------------------------------------------------------
    eq addConvexTag((tagged(PHI1, ('convex > 'true ) ; TS1 ), TFS)) = tagged(PHI1, ('convex > 'true ) ; TS1 ), addConvexTag(TFS)         .
    eq addConvexTag((tagged(PHI1, ('convex > 'false) ; TS1 ), TFS)) = tagged(PHI1, ('convex > 'false) ; TS1 ), addConvexTag(TFS)         .
    eq addConvexTag((tagged(PHI1,                      TS1 ), TFS)) = tagged(PHI1, ('convex > 'false) ; TS1 ), addConvexTag(TFS) [owise] .
    eq addConvexTag(empty) = empty .

    op in-module : Module VariableSet -> VariableSet .
    eq in-module(M1, X1 ; XS) = if wellFormed(M1, X1)
                                then X1
                                else none
                                fi ; in-module(M1, XS) .
    eq in-module(M1, none) = none .

    op var-intersect : VariableSet VariableSet -> VariableSet .
    -------------------------------------------------------
    eq var-intersect(X1 ; XS1, X1 ; XS2) = X1 ; var-intersect(XS1, XS2) .
    eq var-intersect(XS1, XS2)           = none [owise] .
\end{verbatim}

The \texttt{nelson-oppen-valid} function converts a validity check into
a satisfiability check:

\begin{verbatim}
    op nelson-oppen-valid  : TaggedFormulaSet QFForm -> Bool .
    ----------------------------------------------------------
    eq nelson-oppen-valid(TFS, PHI) = strictNot(nelson-oppen-sat(TFS, ~ PHI)) .
\end{verbatim}

The \texttt{nelson-oppen-sat} function that implements the algorithm,
takes as input a \texttt{TaggedFormulaSet} and a quantifier free formula
(of sort \texttt{QFForm}) and returns a \texttt{Bool}.

\begin{verbatim}
    op nelson-oppen-sat    : TaggedFormulaSet QFForm                 -> Bool .
\end{verbatim}

\begin{verbatim}
    op $nosat.dnf          : TaggedFormulaSet QFForm                 -> Bool .
    op $nosat.purified     : TaggedFormulaSet EqConj                 -> Bool .
    op $nosat.tagged       : TaggedFormulaSet                        -> Bool .
    op $nosat.basicSat     : TaggedFormulaSet                        -> Bool .
    op $nosat.ep           : TaggedFormulaSet PosEqDisj              -> Bool .
    op $nosat.split        : TaggedFormulaSet PosEqDisj              -> Bool .
    op $nosat.split.genEqs : TaggedFormulaSet PosEqDisj PosEqDisj    -> Bool .
    --------------------------------------------------------------------------
\end{verbatim}

Given a quantifier free formula \texttt{PHI} in the set of theories
\texttt{TFS} (each tagged with information regarding covexitivity, and
information about which procedure to use for checking sat), we first
convert it to the disjunctive normal form (DNF) and simplify it (e.g.
\(\bot \land \phi\) becomes \(\bot\)).

\begin{verbatim}
    eq nelson-oppen-sat(TFS, PHI)
     = $nosat.dnf(TFS, simplify(toDNF(toNNF(simplify(PHI))))) .
\end{verbatim}

The algorithm then considers each disjunction separately.

\begin{verbatim}
    eq $nosat.dnf(TFS, CONJ \/ PHI)
     =  $nosat.dnf(TFS, CONJ) or-else $nosat.dnf(TFS, PHI)
     .
\end{verbatim}

We then purify each disjunction into a disjunction of ``pure'' atoms
each wellformed in the signature of one of the theories, and tagged with
the appropriate information.

\begin{verbatim}
   ceq $nosat.dnf(TFS , CONJ)
     = $nosat.purified(TFS, purify(ME1, ME2, CONJ))
    if    ( tagged(tt, ('mod > ME1); TS1)
          , tagged(tt, ('mod > ME2); TS2))
       := TFS
     .
    eq $nosat.purified(TFS, CONJ)
     = $nosat.tagged(tagWellFormed(TFS, CONJ)) .
\end{verbatim}

Next, we make sure each of the tagged formulae (\texttt{TF1},
\texttt{TF2}) are satisfiable on their own.

\begin{verbatim}
    eq $nosat.tagged((TF1, TF2))
     = check-sat(TF1) and-then check-sat(TF2) and-then $nosat.basicSat(TF1, TF2)
       [print "Purified:\n\t" TF1 "\n\t" TF2]
     .
\end{verbatim}

From the set of shared variables
\(\SharedVariables := \vars(\phi_1) \intersect \vars(\phi_2)\) we define
a set of candidate equalities.

\[\CandidateEqualities := \{ x_i = y_i | x_i, y_i \in \SharedVariables_{s_i}, x_i \not\equiv y_i \}\]

where \(\SharedVariables_{s_i}\) is the subset of shared variables in
the connected component of sort \(s_i\).

\begin{verbatim}
   ceq $nosat.basicSat(TFS)
     = $nosat.ep( TFS
                , candidate-equalities(in-module(moduleIntersect(ME1, ME2), vars(PHI1) ; vars(PHI2)))
                )
    if ( tagged(PHI1, ('mod > ME1); _1:Tags)
       , tagged(PHI2, ('mod > ME2); _2:Tags))
       :=  TFS
     .
\end{verbatim}

\begin{verbatim}
    op candidate-equalities : VariableSet -> PosEqDisj .
    op candidate-equalities : Variable VariableSet VariableSet -> PosEqDisj .
    ---------------------------------------------------------------------
    eq candidate-equalities(X ; XS1) = candidate-equalities(X, XS1, XS1) .
   ceq candidate-equalities(X, X1 ; XS1, XS2)   = X ?= X1 \/ candidate-equalities(X, XS1, XS2) if     getType(X) == getType(X1) .
   ceq candidate-equalities(X, X1 ; XS1, XS2)   =            candidate-equalities(X, XS1, XS2) if not getType(X) == getType(X1) .
    eq candidate-equalities(X, none, X2 ; XS2)  = candidate-equalities(X2, XS2, XS2) .
    eq candidate-equalities(X, none, none)      = ff .
\end{verbatim}

Next, we apply the equality propagation inference rule. If any
identification of variables is implied by a theory, we propagate that
identification to the other theories.

\begin{verbatim}
   ceq $nosat.ep(( tagged(PHI1, ('mod > ME1); TS1)
                 , tagged(PHI2, ('mod > ME2); TS2)), X1 ?= X2 \/ CANDEQ)
     =          check-sat(tagged(simplify(PHI2 << (X1 <- X2)), ('mod > ME2); TS2))
       and-then $nosat.ep(( tagged(simplify(PHI1 << (X1 <- X2)), ('mod > ME1); TS1)
                          , tagged(simplify(PHI2 << (X1 <- X2)), ('mod > ME2); TS2))
                         , simplify(CANDEQ << (X1 <- X2)))
    if check-valid(tagged(PHI1 => (X1 ?= X2), ('mod > ME1); TS1)) [ print "EqualityProp: " ME1 ": => " X1 " ?= " X2 ] .
\end{verbatim}

If, after checking each identification individually, there are none that
are implied we apply the split rule.

\begin{verbatim}
    eq $nosat.ep(TFS, CANDEQ) = $nosat.split(TFS, CANDEQ) [owise print "=== Split? " TFS CANDEQ ] .
\end{verbatim}

If there are no variables left to identify, then we are satisfiable

\begin{verbatim}
    eq $nosat.split(TFS, mtForm) = true .
\end{verbatim}

However, if there some disjunction of identifications implied and we are
in a non-convex theory, we ``split''. i.e.~we try each of the possible
identification left in turn and see if atleast one of them is
satisfiable.

\begin{verbatim}
   ceq $nosat.split(TFS, CANDEQ)
     = $nosat.split.genEqs(TFS, CANDEQ, CANDEQ)
    if    ( tagged(PHI1, ('mod > ME1) ; ('convex > 'false) ; TS1)
          , tagged(PHI2, ('mod > ME2) ;                      TS2))
       := TFS
    /\ check-valid(tagged((PHI1) => (CANDEQ), ('mod > ME1); ('convex > 'false) ; TS1))
                                            [print "===== Split : "  ME1 " : " PHI1 " => " CANDEQ ]
     .
\end{verbatim}

Otherwise, since there are no implied identifications and the theories
are stably-infinite, the equation is satisfiable.

\begin{verbatim}
    eq $nosat.split(TFS, CANDEQ) = true [owise] .
\end{verbatim}

We use \texttt{\$nosat.split.genEqs} to generate this disequality of sat
problems.

\begin{verbatim}
    eq $nosat.split.genEqs((tagged(PHI1, ('mod > ME1); TS1), tagged(PHI2, ('mod > ME2); TS2))
                          , X1 ?= X2 \/ DISJ?1, X1 ?= X2 \/ DISJ?2)
     = (          check-sat(tagged(PHI1 /\ X1 ?= X2, ('mod > ME1); TS1))
         and-then check-sat(tagged(PHI2 /\ X1 ?= X2, ('mod > ME2); TS2))
         and-then $nosat.ep(( tagged(PHI1 /\ X1 ?= X2, ('mod > ME1); TS1)
                            , tagged(PHI2 /\ X1 ?= X2, ('mod > ME2); TS2))
                           , DISJ?2)
       )
       or-else $nosat.split.genEqs(( tagged(PHI1, ('mod > ME1); TS1)
                                   , tagged(PHI2, ('mod > ME2); TS2))
                               , DISJ?1, X1 ?= X2 \/ DISJ?2)
     .

    eq $nosat.split.genEqs(( tagged(PHI1, ('mod > ME1); TS1)
                           , tagged(PHI2, ('mod > ME2); TS2))
                       , mtForm, DISJ?2)
     = false
     .
endfm
\end{verbatim}

\newcommand \R {\mathbb{R}}

\hypertarget{times-2-matrices-parameterised-over-mathbbr}{%
\section{\texorpdfstring{\(2 \times 2\) matrices parameterised over
\(\mathbb{R}\)}{2 \textbackslash{}times 2 matrices parameterised over \textbackslash{}mathbb\{R\}}}\label{times-2-matrices-parameterised-over-mathbbr}}

In this example, we define the theory of \(2\times 2\) over
\(\mathbb{R}\) and prove that any invertible matrix must have a non-zero
determinant. Unfortunately, CVC4 is not able to solve the non-linear
arithmetic needed to prove this. We must instead use the Yices2, the
other SMT solver available in Maude. Even so, the default configuration
for Yices2 does not enable the solver for non-linear arithmetic (MCSAT),
and running this example involved modifying the Maude source to enable
that configuration.

We define matrices as a four tuple of reals with accessor functions for
each entry.

\begin{verbatim}
set include BOOL off .

fmod MATRIX-REAL is
    sort Real Matrix .
    op matrix : Real Real Real Real -> Matrix [ctor] .
    
    op m11 : Matrix -> Real .
    op m12 : Matrix -> Real .
    op m21 : Matrix -> Real .
    op m22 : Matrix -> Real .

    --- Convince var-sat that Real is an infinite sort.
    op fake-zero :      -> Real [ctor] .
    op fake-succ : Real -> Real [ctor] .

    vars A B C D : Real .

    eq m11(matrix(A, B, C, D)) = A [variant] .
    eq m12(matrix(A, B, C, D)) = B [variant] .
    eq m21(matrix(A, B, C, D)) = C [variant] .
    eq m22(matrix(A, B, C, D)) = D [variant] .
endfm
\end{verbatim}

Since Nelson-Oppen combination does not allow theories to share
functions or predicates, and multiplication and other matrix operations
are defined in terms of the operations in the underlying field, we do
not define it in the previous module and instead define it syntactically
as functions over terms.

\begin{verbatim}
load ../../../contrib/tools/meta/nelson-oppen-combination.maude

fmod TEST is
    protecting NELSON-OPPEN-COMBINATION .

    vars A B A1 B1 A2 B2 ZERO ONE : Term .

    --- Meta level function for generating term representing multiplciation of
    --- matrices
    op mulSum : Term Term Term Term -> Term .
    eq mulSum(A1, B1, A2, B2) = '_+_ [ '_*_ [ A1 , B1 ]
                                     , '_*_ [ A2 , B2 ]
                                     ] .

    op multiply : Term Term -> Term .
    eq multiply(A, B) = 'matrix[ mulSum('m11[A], 'm11[B], 'm12[A], 'm21[B])
                               , mulSum('m11[A], 'm12[B], 'm12[A], 'm22[B])
                               , mulSum('m21[A], 'm11[B], 'm22[A], 'm21[B])
                               , mulSum('m21[A], 'm12[B], 'm22[A], 'm22[B])
                               ] .
    op determinant : Term -> Term .
    eq determinant(A) = '_-_ [ '_*_ [ 'm11[A], 'm22[A] ]
                             , '_*_ [ 'm12[A], 'm21[A] ]
                             ] .
    op identity : Term Term -> Term .
    eq identity(ZERO, ONE) = 'matrix[ONE, ZERO, ZERO, ONE] .
endfm
\end{verbatim}

Finally, we check the validity of the hypothesis that
\(A \times B = I \implies \det(a) \ne 0\) where \(A\), \(B\) and \(I\)
are matrices and \(I\) is the identity.

\begin{verbatim}
set print attribute on .
reduce nelson-oppen-valid(
    ( tagged(tt, (('mod > 'MATRIX-REAL); ('check-sat > 'var-sat)))
    , tagged(tt, (('mod > 'REAL);        ('check-sat > 'smt-sat)))
    ),
       (multiply('A:Matrix, 'B:Matrix) ?= identity('0/1.Real, '1/1.Real))
    => (determinant('A:Matrix) != '0/1.Real)) .
\end{verbatim}

This purifies to the formulae:

\begin{verbatim}
/\ '0/1.Real ?= '_-_['_*_['A11:Real, 'A22:Real],'_*_[ 'A12:Real, 'A21:Real]]
/\ '0Real:Real ?= '0/1.Real
/\ '1Real:Real ?= '1/1.Real 
/\ 'V14:Real ?= '_+_['_*_['A21:Real, 'B12:Real],'_*_[ 'A22:Real, 'B22:Real]] 
/\ 'V5:Real ?= '_+_['_*_['A11:Real, 'B11:Real],'_*_[ 'A12:Real, 'B21:Real]] 
/\ 'V6:Real ?= '_+_['_*_['A11:Real, 'B12:Real],'_*_[ 'A12:Real, 'B22:Real]] 
/\ 'V7:Real ?= '_+_['_*_['A21:Real, 'B11:Real],'_*_[ 'A22:Real, 'B21:Real]] 
\end{verbatim}

\begin{verbatim}
/\ 'A11:Real ?= 'm11['A:Matrix] 
/\ 'A12:Real ?= 'm12['A:Matrix] 
/\ 'A21:Real ?= 'm21['A:Matrix] 
/\ 'A22:Real ?= 'm22['A:Matrix] 
/\ 'B11:Real ?= 'm11['B:Matrix] 
/\ 'B12:Real ?= 'm12['B:Matrix] 
/\ 'B21:Real ?= 'm21['B:Matrix] 
/\ 'B22:Real ?= 'm22['B:Matrix] 
/\     'matrix['1Real:Real,'0Real:Real, '0Real:Real,'1Real:Real]
    ?= 'matrix['V5:Real,'V6:Real,'V7:Real,'V14:Real]
\end{verbatim}

Each theory propogates equalities:

\begin{verbatim}
EqualityProp: 'MATRIX-REAL: => '0Real:Real ?= 'V6:Real
EqualityProp: 'MATRIX-REAL: => '1Real:Real ?= 'V5:Real
EqualityProp: 'REAL:        => 'V6:Real    ?= 'V14:Real
EqualityProp: 'MATRIX-REAL: => 'V5:Real    ?= 'V7:Real
EqualityProp: 'REAL:        => 'A11:Real   ?= 'A21:Real
EqualityProp: 'REAL:        => 'A12:Real   ?= 'A22:Real
EqualityProp: 'MATRIX-REAL: => 'V7:Real    ?= 'V14:Real
\end{verbatim}

We define Matrices in terms of an undefined sort \texttt{X}, without any
functions such as multiplication. This is because multiplication must be
defined in terms of the underlying field's multiplication operator and
Nelson-Oppen combination does not allow sharing of function symbols.

\begin{verbatim}
set include BOOL off .

fmod MATRIX-X is
    sort X Matrix .
    op matrix : X X X X -> Matrix [ctor] .

    vars A B C D : X .
    op m11 : Matrix -> X .
    op m12 : Matrix -> X .
    op m21 : Matrix -> X .
    op m22 : Matrix -> X .

    eq m11(matrix(A, B, C, D)) = A [variant] .
    eq m12(matrix(A, B, C, D)) = B [variant] .
    eq m21(matrix(A, B, C, D)) = C [variant] .
    eq m22(matrix(A, B, C, D)) = D [variant] .
endfm
\end{verbatim}

We the define parameterise this theory over the reals and the integers:

\begin{verbatim}
fmod MATRIX-REAL is
    including MATRIX-X .
    sort Real .
    subsorts Real < X .
    --- Convince var-sat that Real is an infinite sort.
    op fake-zero :      -> Real [ctor] .
    op fake-succ : Real -> Real [ctor] .
endfm
\end{verbatim}

\begin{verbatim}
fmod MATRIX-INTEGER is
    including MATRIX-X .
    sort Integer .
    subsorts Integer < X .
    --- Convince var-sat that Integer is an infinite sort.
    op fake-zero :         -> Integer [ctor] .
    op fake-succ : Integer -> Integer [ctor] .
endfm
\end{verbatim}

We define multiplciation and the calculation of the determinant as
meta-functions defining them syntactically, in terms of the fields
multiplication and addition operators.

\begin{verbatim}
load ../../../contrib/tools/meta/nelson-oppen-combination.maude

fmod TEST is
    protecting NELSON-OPPEN-COMBINATION .

    vars A B A1 B1 A2 B2 ZERO ONE : Term .

    --- Meta level function for generating term representing multiplciation of
    --- matrices
    op mulSum : Term Term Term Term -> Term .
    eq mulSum(A1, B1, A2, B2) = '_+_ [ '_*_ [ A1 , B1 ]
                                     , '_*_ [ A2 , B2 ]
                                     ] .

    op multiply : Term Term -> Term .
    eq multiply(A, B) = 'matrix[ mulSum('m11[A], 'm11[B], 'm12[A], 'm21[B])
                               , mulSum('m11[A], 'm12[B], 'm12[A], 'm22[B])
                               , mulSum('m21[A], 'm11[B], 'm22[A], 'm21[B])
                               , mulSum('m21[A], 'm12[B], 'm22[A], 'm22[B])
                               ] .
    op determinant : Term -> Term .
    eq determinant(A) = '_-_ [ '_*_ [ 'm11[A], 'm22[A] ]
                             , '_*_ [ 'm12[A], 'm21[A] ]
                             ] .

    op identity : Term Term -> Term .
    eq identity(ZERO, ONE) = 'matrix[ONE, ZERO, ZERO, ONE] .

endfm
\end{verbatim}

\begin{verbatim}

--- x reduce smt-sat('INTEGER,
--- x     (   '_*_['A11:Integer, 'B11:Integer] ?= '1.Integer
--- x     /\  '_*_['A22:Integer, 'B22:Integer] ?= '1.Integer
--- x     ) =>
--- x     (  '_*_['A11:Integer, 'A22:Integer] ?= '1.Integer
--- x ---    /\ '_*_['B1:Integer, 'B2:Integer] ?= '1.Integer 
--- x     )
--- x     )
--- x     .

--- set trace on .
--- set trace condition off .
--- set trace select on .
--- trace select $nosat.ep check-sat .
set print attribute on .

reduce nelson-oppen-valid(( tagged(tt, (('mod > 'MATRIX-INTEGER);  ('check-sat > 'var-sat); ('convex > 'true)))
                        , tagged(tt, (('mod > 'INTEGER       );  ('check-sat > 'smt-sat); ('convex > 'false)))),
       (    multiply('A:Matrix, 'B:Matrix) ?= identity('0.Integer, '1.Integer)
         /\ 'm21['A:Matrix] ?= '0.Integer
       )
    => ( determinant('A:Matrix) ?= '1.Integer
      \/ determinant('A:Matrix) ?= '-_['1.Integer]
       )
   ) .
eof .

reduce wellFormed(upModule('INTEGER, true), '1.Integer) .
reduce wellFormed(upModule('REAL-INTEGER, true), '1.Integer) .
reduce wellFormed(upModule('REAL, true), '1/1.Real) .
reduce wellFormed(upModule('REAL, true), '_*_[ 'x:Real, 'x:Real ]) .
reduce wellFormed(upModule('REAL, true), '0/1.Real) .

reduce smt-sat('INTEGER, '1.Integer ?= '0.Integer) .
reduce smt-sat('REAL,    '0/5.Real ?= '0/1.Real) .
reduce smt-sat('REAL-INTEGER, '_*_[ 'x:Real, 'x:Real ] ?= '0/1.Real) .
reduce smt-sat('REAL,
                  '_*_[ 'X:Real, 'X:Real ] ?= '0/1.Real
               /\ '_*_[ 'Y:Real, 'Y:Real ] ?= '0/1.Real
               /\ 'X:Real != 'Y:Real
              ) .
reduce smt-sat('REAL,
                  '_*_[ 'X:Real, 'X:Real ] ?= '1/1.Real
               /\ '_*_[ 'Y:Real, 'Y:Real ] ?= '1/1.Real
               /\ 'X:Real != 'Y:Real
              ) .

reduce smt-sat('INTEGER,
                  ('_*_[ 'X:Integer, 'Y:Integer ] ?= '0.Integer)
               => (  ('X:Integer ?= '0.Integer)
                  \/ ('Y:Integer ?= '0.Integer))
              ) .
reduce purify( upModule('MATRIX-INTEGER, true), upModule('INTEGER, true)
             , identity('0.Integer, '1.Integer)) .
\end{verbatim}

\begin{verbatim}
set print attribute on .

---
--- --- Are there invertible (real) matrices whos determinants are two?
---
--- reduce nelson-oppen-sat(( tagged(tt, (('mod > 'MATRIX-REAL);  ('check-sat > 'var-sat); ('convex > 'true)))
---                         , tagged(tt, (('mod > 'REAL);         ('check-sat > 'smt-sat); ('convex > 'false)))),
---           multiply('A:Matrix, 'B:Matrix) ?= identity('0/1.Real, '1/1.Real)
---        /\ determinant('A:Matrix) ?= '2/1.Real
---        ) .


--- Are there invertible (integer) matrices whos determinants are two?

--- reduce smt-sat('INTEGER,
---            'V4:Integer ?= '1.Integer
--- 		/\ 'V4:Integer ?= '_+_['_*_['A11:Integer,'B11:Integer],'_*_['A12:Integer,'B21:Integer]]
--- 		/\ 'V3:Integer ?= '0.Integer
--- 		/\ 'V3:Integer ?= '_+_['_*_['A11:Integer,'B12:Integer],'_*_['A12:Integer,'B22:Integer]]
--- 		/\ 'V2:Integer ?= '_+_['_*_['A21:Integer,'B11:Integer],'_*_['A22:Integer,'B21:Integer]]
--- 		/\ 'V13:Integer ?= '_+_['_*_['A21:Integer,'B12:Integer],'_*_['A22:Integer,'B22:Integer]]
--- 		/\ 'V13:Integer != 'A22:Integer) .
\end{verbatim}

\hypertarget{conclusion-future-work}{%
\section{Conclusion \& Future work}\label{conclusion-future-work}}

The examples above have demonstrated the usefulness of Nelson-Oppen
combination in Maude. Even so, the tool is still a prototype. There are
several avenues that need to be explored before fully exploiting its
potential. An obvious generalization is to handle combinations of more
than two theories. One obvious and simple generalization to make is to
have the module take more than two theories. Another is to accept a
wider variety of theories.

Stable infiniteness requires that the theory has infinite models.
However, there are several important theories that are not stably
infinite. For example, the theory of bit vectors (\(\Z / 2^n\Z\)) can be
used to model ``machine integers'' widely used in many programming
languages. In {[}shiny{]}, Tinelli and Zarba showed that this
requirement can be reduced to the case where all but one of the theories
is ``shiny''. Further work by Ranise, Ringeissen and Zarba{[}@polite{]},
and by Jovanovi and Barrett{[}@politerevisited{]} provided an easier to
compute alternative called strongly ``polite'' theories. Extending this
implementation to handle these cases would greatly expand the usefulness
of these theories.

Being a prototype, little effort has been spent on optimization. For
example, when working with the \texttt{var-sat} solver, the list of most
general unifiers is computed repeatedly at every at every query to the
solver. Computing this list can be expensive depending on the term and
theory under consideration. For example, in an extreme case the term
\texttt{\{\ X:Magma,\ Y:Magma,\ Z:Magma\ \}\ C=\ \{\ X:Magma\ \}} took
tens of minutes to compute.

Another possible optimization is to take advantage of the propositional
structure of the formula through combination with a boolean SAT solver.
The DPLL is an algorithm for deciding the satisfiablilty of
propositional logic formulae and forms the basis of most modern
efficient solver {[}@krstic2007architecting{]}.

In general, one can envision incrementally building up towards a
flexible, efficient and powerful SMT infrastructure in Maude delegating
both to external solvers as well as tools leveraging the power and
expressiveness of rewriting logic.

\end{document}
